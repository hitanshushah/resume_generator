version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
      args:
          BACKEND_PORT: ${BACKEND_PORT} 
    volumes:
      - ./backend:/app
      - /app/__pycache__
    env_file:
      - .env
    ports:
      - "${BACKEND_PORT}:${BACKEND_PORT}"
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend-next
      dockerfile: Dockerfile.dev
      args:
        NEXT_PORT: ${NEXT_PORT} 
    volumes:
      - ./frontend-next:/app
      - /app/node_modules
    env_file:
      - .env
    ports:
      - "${NEXT_PORT}:${NEXT_PORT}"
    depends_on:
      - backend
    restart: unless-stopped

  ollama:
    build:
      context: ./ollama
      dockerfile: Dockerfile
      args:
        OLLAMA_MODEL: ${OLLAMA_MODEL}
        OLLAMA_PORT: ${OLLAMA_PORT}
    volumes:
      - ./ollama-models:/root/.ollama
    env_file:
      - .env
    ports:
      - "${OLLAMA_PORT}:${OLLAMA_PORT}"
    mem_limit: 8g
    restart: unless-stopped
